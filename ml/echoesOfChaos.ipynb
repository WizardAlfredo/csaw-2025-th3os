{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "278944d8",
   "metadata": {},
   "source": [
    "## Echoes Of Chaos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "52dbfef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCOPETYPE = 'CWNANO'\n",
    "PLATFORM = 'CWNANO'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "53038a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(ChipWhisperer NAEUSB WARNING|File naeusb.py:826) Your firmware (0.65.0) is outdated - latest is 0.66.0 See https://chipwhisperer.readthedocs.io/en/latest/firmware.html for more information\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Caught exception on reconnecting to target - attempting to reconnect to scope first.\n",
      "INFO: This is a work-around when USB has died without Python knowing. Ignore errors above this line.\n",
      "INFO: Found ChipWhispererðŸ˜\n"
     ]
    }
   ],
   "source": [
    "%run \"../setup/Setup_Generic.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "142a9e07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected known STMF32: STM32F04xxx\n",
      "Extended erase (0x44), this can take ten seconds or more\n",
      "Attempting to program 14307 bytes at 0x8000000\n",
      "STM32F Programming flash...\n",
      "STM32F Reading flash...\n",
      "Verified flash OK, 14307 bytes\n"
     ]
    }
   ],
   "source": [
    "cw.program_target(scope, prog, \"chaos-{}.hex\".format(PLATFORM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "256c9376-38da-48e8-a385-9fb8617320a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(ChipWhisperer NAEUSB WARNING|File naeusb.py:826) Your firmware (0.65.0) is outdated - latest is 0.66.0 See https://chipwhisperer.readthedocs.io/en/latest/firmware.html for more information\n",
      "/tmp/ipykernel_263281/339471976.py:161: RuntimeWarning: overflow encountered in exp\n",
      "  probs = 1 / (1 + np.exp(-logits))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] index 0 -> 27965\n",
      "[+] index 1 -> 698\n",
      "[+] index 2 -> 45997\n",
      "[+] index 3 -> 36081\n",
      "[+] index 4 -> 58773\n",
      "[+] index 5 -> 9093\n",
      "[+] index 6 -> 42350\n",
      "[+] index 7 -> 6537\n",
      "[+] index 8 -> 13984\n",
      "[+] index 9 -> 25987\n",
      "[+] index 10 -> 64749\n",
      "[+] index 11 -> 64987\n",
      "[+] index 12 -> 29601\n",
      "[+] index 13 -> 49205\n",
      "[+] index 14 -> 19618\n",
      "[*] recovered (unsorted): [27965, 698, 45997, 36081, 58773, 9093, 42350, 6537, 13984, 25987, 64749, 64987, 29601, 49205, 19618]\n",
      "[*] recovered (bias-fixed, sorted): [697, 6536, 9092, 13983, 19617, 25986, 27964, 29600, 36080, 42349, 45996, 49204, 58772, 64748, 64986]\n",
      "[*] FLAG: eoc{th3yreC00ked}   \n",
      "[*] queries used: 466\n"
     ]
    }
   ],
   "source": [
    "import struct, time\n",
    "import numpy as np\n",
    "import chipwhisperer as cw\n",
    "\n",
    "# try to import torch\n",
    "try:\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    import torch.optim as optim\n",
    "\n",
    "# ----------------------------\n",
    "# config\n",
    "# ----------------------------\n",
    "ARR_LEN = 15\n",
    "TRACE_KEEP = 3000\n",
    "N_LEVELS = 8\n",
    "SUBDIV = 4\n",
    "LOCAL_MARGIN = 4        # DL will look at [lo-4 .. hi+4]\n",
    "DL_EPOCHS = 50\n",
    "DL_LR = 1e-2\n",
    "\n",
    "scope = cw.scope()\n",
    "target = cw.target(scope, cw.targets.SimpleSerial)\n",
    "scope.adc.samples = 100000\n",
    "\n",
    "trace_cache = {}\n",
    "\n",
    "# ----------------------------\n",
    "# device helpers\n",
    "# ----------------------------\n",
    "def reset_ss():\n",
    "    target.simpleserial_write('x', b\"\")\n",
    "    _ = target.simpleserial_read('r', 1)\n",
    "\n",
    "def num_q():\n",
    "    target.simpleserial_write('q', b\"0\")\n",
    "    resp = target.simpleserial_read('r', 4)\n",
    "    return struct.unpack(\"<I\", resp)[0]\n",
    "\n",
    "def capture_val_skip(v, skip):\n",
    "    low, high = struct.pack('<H', v)\n",
    "    pkt = [0, low, high, skip]\n",
    "    scope.arm()\n",
    "    target.simpleserial_write('p', bytes(pkt))\n",
    "    timeout = scope.capture()\n",
    "    if timeout:\n",
    "        raise RuntimeError(\"capture timeout\")\n",
    "    _ = target.simpleserial_read('r', 1)\n",
    "    return scope.get_last_trace()[:TRACE_KEEP].copy()\n",
    "\n",
    "def get_trace(v, skip):\n",
    "    key = (v, skip)\n",
    "    if key not in trace_cache:\n",
    "        reset_ss()\n",
    "        trace_cache[key] = capture_val_skip(v, skip)\n",
    "    return trace_cache[key]\n",
    "\n",
    "def check_arr_exact_15(vals):\n",
    "    vals = sorted(vals)\n",
    "    bs = []\n",
    "    for v in vals:\n",
    "        lo, hi = struct.pack('<H', v)\n",
    "        bs.append(lo); bs.append(hi)\n",
    "    scope.arm()\n",
    "    target.simpleserial_write('a', bytes(bs))\n",
    "    timeout = scope.capture()\n",
    "    if timeout:\n",
    "        raise RuntimeError(\"timeout in 'a'\")\n",
    "    resp = target.simpleserial_read('r', 20)\n",
    "    _ = scope.get_last_trace()\n",
    "    return resp.decode(errors=\"ignore\")\n",
    "\n",
    "# ----------------------------\n",
    "# projector per skip\n",
    "# ----------------------------\n",
    "def build_discriminant_for_skip(skip):\n",
    "    # avg 2 shots\n",
    "    t_small = 0.5 * (get_trace(0, skip).astype(np.float32) +\n",
    "                     get_trace(0, skip).astype(np.float32))\n",
    "    t_big   = 0.5 * (get_trace(65535, skip).astype(np.float32) +\n",
    "                     get_trace(65535, skip).astype(np.float32))\n",
    "\n",
    "    w = t_small - t_big\n",
    "    s_small = float(np.dot(t_small, w))\n",
    "    s_big   = float(np.dot(t_big,   w))\n",
    "    thresh  = 0.5 * (s_small + s_big)\n",
    "    return w, thresh\n",
    "\n",
    "def score_trace(tr, w):\n",
    "    return float(np.dot(tr, w))\n",
    "\n",
    "# ----------------------------\n",
    "# tiny local DL model\n",
    "# ----------------------------\n",
    "class Tiny1DCNN(nn.Module):\n",
    "    def __init__(self, in_len):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 8, kernel_size=9, padding=4)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool1d(2)\n",
    "        self.conv2 = nn.Conv1d(8, 16, kernel_size=7, padding=3)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool1d(2)\n",
    "        L = in_len // 2\n",
    "        L = L // 2\n",
    "        self.fc1 = nn.Linear(16 * L, 32)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x); x = self.relu1(x); x = self.pool1(x)\n",
    "        x = self.conv2(x); x = self.relu2(x); x = self.pool2(x)\n",
    "        x = x.flatten(1)\n",
    "        x = self.fc1(x); x = self.relu3(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "def deep_refine(skip, w, thresh, lo, hi):\n",
    "\n",
    "    win_lo = max(0, lo - LOCAL_MARGIN)\n",
    "    win_hi = min(0xFFFF, hi + LOCAL_MARGIN)\n",
    "    cand_vals = list(range(win_lo, win_hi + 1))\n",
    "\n",
    "    traces = []\n",
    "    labels = []\n",
    "    for v in cand_vals:\n",
    "        tr = get_trace(v, skip).astype(np.float32)\n",
    "        tr = (tr - tr.mean()) / (tr.std() + 1e-6)\n",
    "        traces.append(tr)\n",
    "        sc = score_trace(tr, w)\n",
    "        lab = 1 if sc < thresh else 0   # BIG=1\n",
    "        labels.append(lab)\n",
    "\n",
    "    traces = np.stack(traces, axis=0)\n",
    "    labels = np.array(labels, dtype=np.float32)[:, None]\n",
    "\n",
    "    L = traces.shape[1]\n",
    "    model = Tiny1DCNN(L)\n",
    "    crit = nn.BCEWithLogitsLoss()\n",
    "    opt = optim.Adam(model.parameters(), lr=DL_LR)\n",
    "\n",
    "    x_t = torch.from_numpy(traces).unsqueeze(1)\n",
    "    y_t = torch.from_numpy(labels)\n",
    "\n",
    "    model.train()\n",
    "    for _ in range(DL_EPOCHS):\n",
    "        opt.zero_grad()\n",
    "        out = model(x_t)\n",
    "        loss = crit(out, y_t)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(x_t).squeeze(1).numpy()\n",
    "        probs = 1 / (1 + np.exp(-logits))\n",
    "    big_idxs = [i for i, p in enumerate(probs) if p > 0.5]\n",
    "    if not big_idxs:\n",
    "        return max(0, hi - 1)\n",
    "    best_idx = min(big_idxs)\n",
    "    return cand_vals[best_idx]\n",
    "\n",
    "# ----------------------------\n",
    "# multiresolution\n",
    "# ----------------------------\n",
    "def find_value_for_skip(skip):\n",
    "    w, thresh = build_discriminant_for_skip(skip)\n",
    "    active = [(0, 65535, True, False)]\n",
    "    for _ in range(N_LEVELS):\n",
    "        new_active = []\n",
    "        for (lo, hi, lo_small, hi_small) in active:\n",
    "            if lo_small == hi_small:\n",
    "                continue\n",
    "            span = hi - lo\n",
    "            if span <= 1:\n",
    "                new_active.append((lo, hi, lo_small, hi_small))\n",
    "                continue\n",
    "            step = max(span // SUBDIV, 1)\n",
    "            points = [lo + k * step for k in range(1, SUBDIV)]\n",
    "            if points and points[-1] >= hi:\n",
    "                points = points[:-1]\n",
    "            samples = [(lo, lo_small)]\n",
    "            for p in points:\n",
    "                tr_p = get_trace(p, skip)\n",
    "                sc_p = score_trace(tr_p, w)\n",
    "                cls_p = (sc_p >= thresh)\n",
    "                samples.append((p, cls_p))\n",
    "            samples.append((hi, hi_small))\n",
    "            for i in range(len(samples)-1):\n",
    "                x0, c0 = samples[i]\n",
    "                x1, c1 = samples[i+1]\n",
    "                if c0 != c1:\n",
    "                    new_active.append((x0, x1, c0, c1))\n",
    "        active = new_active\n",
    "        if not active:\n",
    "            break\n",
    "    if not active:\n",
    "        return 0\n",
    "    best_seg = min(active, key=lambda s: s[1])\n",
    "    lo, hi, _, _ = best_seg\n",
    "    val = deep_refine(skip, w, thresh, lo, hi)\n",
    "    return val\n",
    "\n",
    "# ----------------------------\n",
    "# main\n",
    "# ----------------------------\n",
    "reset_ss()\n",
    "start_q = num_q()\n",
    "\n",
    "recovered = []\n",
    "for skip in range(ARR_LEN):\n",
    "    v = find_value_for_skip(skip)\n",
    "    recovered.append(v)\n",
    "    print(f\"[+] index {skip} -> {v}\")\n",
    "\n",
    "print(\"[*] recovered (unsorted):\", recovered)\n",
    "\n",
    "recovered = [max(0, v - 1) for v in recovered]\n",
    "\n",
    "recovered_sorted = sorted(recovered)\n",
    "print(\"[*] recovered (bias-fixed, sorted):\", recovered_sorted)\n",
    "\n",
    "flag = check_arr_exact_15(recovered_sorted)\n",
    "end_q = num_q()\n",
    "print(\"[*] FLAG:\", flag)\n",
    "print(\"[*] queries used:\", end_q - start_q)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "aa42f681-50f7-4eb1-a983-bb5d5cd068c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(ChipWhisperer NAEUSB WARNING|File naeusb.py:826) Your firmware (0.65.0) is outdated - latest is 0.66.0 See https://chipwhisperer.readthedocs.io/en/latest/firmware.html for more information\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] index 0 -> 27965\n",
      "[+] index 1 -> 698\n",
      "[+] index 2 -> 45997\n",
      "[+] index 3 -> 36081\n",
      "[+] index 4 -> 58773\n",
      "[+] index 5 -> 9093\n",
      "[+] index 6 -> 42350\n",
      "[+] index 7 -> 6537\n",
      "[+] index 8 -> 13984\n",
      "[+] index 9 -> 25987\n",
      "[+] index 10 -> 64749\n",
      "[+] index 11 -> 64987\n",
      "[+] index 12 -> 29601\n",
      "[+] index 13 -> 49205\n",
      "[+] index 14 -> 19618\n",
      "[*] recovered (unsorted): [27965, 698, 45997, 36081, 58773, 9093, 42350, 6537, 13984, 25987, 64749, 64987, 29601, 49205, 19618]\n",
      "[*] recovered (bias-fixed, sorted): [697, 6536, 9092, 13983, 19617, 25986, 27964, 29600, 36080, 42349, 45996, 49204, 58772, 64748, 64986]\n",
      "[*] FLAG: eoc{th3yreC00ked}   \n",
      "[*] queries used: 271\n"
     ]
    }
   ],
   "source": [
    "import struct, time\n",
    "import numpy as np\n",
    "import chipwhisperer as cw\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "# ----------------------------\n",
    "# config\n",
    "# ----------------------------\n",
    "ARR_LEN = 15\n",
    "TRACE_KEEP = 3000\n",
    "MAX_VAL = 0xFFFF\n",
    "\n",
    "scope = cw.scope()\n",
    "target = cw.target(scope, cw.targets.SimpleSerial)\n",
    "scope.adc.samples = 100000\n",
    "\n",
    "trace_cache = {}\n",
    "\n",
    "# ----------------------------\n",
    "# device helpers\n",
    "# ----------------------------\n",
    "def reset_ss():\n",
    "    target.simpleserial_write('x', b\"\")\n",
    "    _ = target.simpleserial_read('r', 1)\n",
    "\n",
    "def num_q():\n",
    "    target.simpleserial_write('q', b\"0\")\n",
    "    resp = target.simpleserial_read('r', 4)\n",
    "    return struct.unpack(\"<I\", resp)[0]\n",
    "\n",
    "def capture_val_skip(v, skip):\n",
    "    low, high = struct.pack('<H', v)\n",
    "    pkt = [0, low, high, skip]\n",
    "    scope.arm()\n",
    "    target.simpleserial_write('p', bytes(pkt))\n",
    "    timeout = scope.capture()\n",
    "    if timeout:\n",
    "        raise RuntimeError(\"capture timeout\")\n",
    "    _ = target.simpleserial_read('r', 1)\n",
    "    return scope.get_last_trace()[:TRACE_KEEP].copy()\n",
    "\n",
    "def get_trace(v, skip):\n",
    "    key = (v, skip)\n",
    "    if key not in trace_cache:\n",
    "        reset_ss()\n",
    "        trace_cache[key] = capture_val_skip(v, skip)\n",
    "    return trace_cache[key]\n",
    "\n",
    "def check_arr_exact_15(vals):\n",
    "    vals = sorted(vals)\n",
    "    bs = []\n",
    "    for v in vals:\n",
    "        lo, hi = struct.pack('<H', v)\n",
    "        bs.append(lo); bs.append(hi)\n",
    "    scope.arm()\n",
    "    target.simpleserial_write('a', bytes(bs))\n",
    "    timeout = scope.capture()\n",
    "    if timeout:\n",
    "        raise RuntimeError(\"timeout in 'a'\")\n",
    "    resp = target.simpleserial_read('r', 20)\n",
    "    _ = scope.get_last_trace()\n",
    "    return resp.decode(errors=\"ignore\")\n",
    "\n",
    "# ----------------------------\n",
    "# per-skip ML+binary-search\n",
    "# ----------------------------\n",
    "def recover_one(skip):\n",
    "    # 1) anchor examples: 0 = SMALL, 65535 = BIG\n",
    "    tr_small = get_trace(0, skip)\n",
    "    tr_big   = get_trace(65535, skip)\n",
    "    X = np.vstack([tr_small, tr_big])\n",
    "    y = np.array([1, 0], dtype=np.int32)   # 1=SMALL, 0=BIG\n",
    "\n",
    "    # linear classifier; we'll also update as we go\n",
    "    clf = SGDClassifier(loss=\"log_loss\", max_iter=5, tol=None)\n",
    "    clf.fit(X, y)\n",
    "\n",
    "    lo, hi = 0, MAX_VAL\n",
    "    # classic lower_bound on \"is BIG?\"\n",
    "    while lo < hi:\n",
    "        mid = (lo + hi) // 2\n",
    "        tr_mid = get_trace(mid, skip)\n",
    "        # predict\n",
    "        pred = clf.predict(tr_mid.reshape(1, -1))[0]   # 1=SMALL, 0=BIG\n",
    "        # optional: on-the-fly adaptation\n",
    "        clf.partial_fit(tr_mid.reshape(1, -1), np.array([pred]))\n",
    "        if pred == 1:  # SMALL â†’ go right\n",
    "            lo = mid + 1\n",
    "        else:          # BIG â†’ go left\n",
    "            hi = mid\n",
    "    cand = lo\n",
    "\n",
    "    # one-step local correction (this board tends to land on upper side)\n",
    "    if cand > 0:\n",
    "        tr_prev = get_trace(cand - 1, skip)\n",
    "        pred_prev = clf.predict(tr_prev.reshape(1, -1))[0]\n",
    "        if pred_prev == 0:  # also BIG\n",
    "            cand = cand - 1\n",
    "\n",
    "    return cand\n",
    "\n",
    "# ----------------------------\n",
    "# main\n",
    "# ----------------------------\n",
    "reset_ss()\n",
    "start_queries = num_q()\n",
    "\n",
    "recovered = []\n",
    "for skip in range(ARR_LEN):\n",
    "    v = recover_one(skip)\n",
    "    recovered.append(v)\n",
    "    print(f\"[+] index {skip} -> {v}\")\n",
    "\n",
    "print(\"[*] recovered (unsorted):\", recovered)\n",
    "\n",
    "# your required bias-fix\n",
    "recovered = [max(0, v - 1) for v in recovered]\n",
    "\n",
    "recovered_sorted = sorted(recovered)\n",
    "print(\"[*] recovered (bias-fixed, sorted):\", recovered_sorted)\n",
    "\n",
    "flag = check_arr_exact_15(recovered_sorted)\n",
    "end_queries = num_q()\n",
    "\n",
    "print(\"[*] FLAG:\", flag)\n",
    "print(\"[*] queries used:\", end_queries - start_queries)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d09372d-3083-4876-aede-42dfecd439c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
